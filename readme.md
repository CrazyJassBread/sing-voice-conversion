# Sing Voice Conversion
è¯­éŸ³æŠ€æœ¯è¯¾ç¨‹é¡¹ç›®
[result](https://box.nju.edu.cn/d/0ddd3ea0a83f49e7af94/)

ä¸€å…±åˆ†æˆäº†ä¸‰ä¸ªéƒ¨åˆ†ï¼Œ

- æ­Œæ›²é¢„å¤„ç†ï¼ˆäººå£°ä¼´å¥åˆ†ç¦»ï¼‰ï¼š**accom_separation**
- Sing Voice Conversionï¼š**seed-vc DDSP-SVC**
- æœ‰ç”¨çš„å·¥å…·å‡½æ•°ï¼š**utils**

## accom_separation

è¿™ä¸€éƒ¨åˆ†çš„ä»£ç æ¥è‡ª[YingMusic-SVC](https://github.com/GiantAILab/YingMusic-SVC)ï¼Œå¯ä»¥é€šè¿‡è¿è¡Œ `infer.sh` æ–‡ä»¶æ¥å¯¹æ­Œæ›²è¿›è¡Œäººå£°ã€ä¼´å¥çš„æå–

```
cd accom_separation
pip install -r requirements.txt
bash infer.sh
```

éœ€è¦çš„é¢„è®­ç»ƒæ¨¡å‹ [![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20HuggingFace-BR--separator-yellow)](https://huggingface.co/GiantAILab/YingMusic-SVC/blob/main/bs_roformer.ckpt) 

## seed-vc

ä»£ç æ¥è‡ª[seed vc](https://github.com/Plachtaa/seed-vc)
é…ç½®çš„è¯¦ç»†å†…å®¹å‚è€ƒ[README](seed-vc/README.md)

å¾®è°ƒçš„å“ˆå‰ç±³æ¨¡å‹ğŸ‘‰[model](https://box.nju.edu.cn/d/6b31d2cb97334078b14e/)

æµ‹è¯•æ—¶åªéœ€è¦å°†æ¨¡å‹ä¸‹è½½ç„¶åè¿è¡Œ
```
cd seed-vc

python app_svc.py --checkpoint <path-to-checkpoint> --config <path-to-config> --fp16 True
```
- <path-to-checkpoint> ä¿®æ”¹ä¸ºmodelçš„è·¯å¾„
- <path-to-config> ä¿®æ”¹ä¸ºå¯¹åº”configçš„è·¯å¾„

## DDSP-SVC

ä»£ç æ¥è‡ª[DDSP-SVC](https://github.com/yxlllc/DDSP-SVC)
é…ç½®çš„è¯¦ç»†å†…å®¹å‚è€ƒ[cn_README](https://github.com/yxlllc/DDSP-SVC/blob/master/cn_README.md)

åŒæ ·æ˜¯å¾®è°ƒçš„å“ˆå‰ç±³æ¨¡å‹ğŸ˜Š[model](https://box.nju.edu.cn/d/8ec999f01dd74365b00a/)

è¿›è¡Œæ­Œå£°è½¬æ¢æ—¶éœ€è¦å°†æ¨¡å‹å’Œé…ç½®æ–‡ä»¶config.yamlä¸‹è½½åæ”¾åˆ°é…ç½®æ–‡ä»¶æŒ‡å®šçš„è·¯å¾„expdirä¸‹(é»˜è®¤å€¼æ˜¯exp/diffusion-test)
```
cd DDSP-SVC

python main_diff.py -i <input.wav> -diff <diff_ckpt.pt> -o <output.wav> -k <keychange (semitones)> -id <speaker_id> -speedup <speedup> -method <method> -kstep <kstep>
```
- `<input.wav>` ä¿®æ”¹ä¸ºæ­Œæ›²çš„è·¯å¾„
- `<diff_ckpt.pt>` ä¿®æ”¹ä¸ºå£°ç å™¨çš„è·¯å¾„(ä»¥NSF-HIFIGANå£°ç å™¨ä¸ºä¾‹ï¼Œé»˜è®¤è·¯å¾„ä¸ºpretrain/nsf_hifigan/model)
- `<output.wav>` ä¿®æ”¹ä¸ºä¿å­˜è½¬æ¢åçš„æ­Œæ›²çš„è·¯å¾„
- `<keychange (semitones)>` ç”¨äºè°ƒèŠ‚éŸ³é¢‘çš„éŸ³é«˜ï¼Œæ­£å¸¸è®¾ä¸º0
- `<speaker_id>` æ­Œæ‰‹çš„idï¼Œå¡«ä¸€ä¸ªæ•´æ•°å³å¯
- `<speedup>` æ­Œæ›²æ’­æ”¾é€Ÿåº¦ï¼Œæ­£å¸¸è®¾ä¸º1ï¼Œè¯·ä¸è¦å°†speedupçš„å€¼è®¾çš„è¿‡é«˜ï¼Œ**speedup è¶…è¿‡ 20 æ—¶å¯èƒ½å°†æ„ŸçŸ¥åˆ°éŸ³è´¨æŸå¤±**ã€‚
- `<method>` æœ‰ddim, pndm, dpm-solverå’Œunipcå››ç§æ–¹æ³•å¯ä¾›é€‰æ‹©
- `<kstep>` kstep ä¸ºæµ…æ‰©æ•£æ­¥æ•°ï¼Œåˆç†çš„èŒƒå›´ä¸º100~300

## RIFT-SVC
ä»£ç æ¥è‡ª[RIFT-SVC](https://github.com/Pur1zumu/RIFT-SVC#)
é…ç½®æŒ‰ç…§ [README](https://github.com/Pur1zumu/RIFT-SVC/blob/master/README.md) ä¸­æç¤ºçš„æ­¥éª¤è¿›è¡Œå³å¯

é…ç½®å¥½è¿è¡Œç¯å¢ƒåï¼Œéœ€è¦å…ˆä¸‹è½½ç”¨äºå¾®è°ƒçš„é¢„è®­ç»ƒæƒé‡
```bash
wget https://huggingface.co/Pur1zumu/RIFT-SVC-pretrained/resolve/main/pretrain-v3_dit-768-12.ckpt -O pretrained/pretrain-v3_dit-768-12.ckpt
```

å°†è½¬æ¢ç›®æ ‡äººç‰©çš„å£°éŸ³æ–‡ä»¶æ”¾å…¥ data/finetune æ–‡ä»¶å¤¹ä¸­ï¼Œå…ˆè¿›è¡Œé‡é‡‡æ ·ï¼Œå†è¿›è¡Œ f0, mel, cvec ç­‰ç‰¹å¾çš„æå–ï¼Œè¿›è¡Œæ¨¡å‹çš„å¾®è°ƒ

å¾®è°ƒå®Œæˆåï¼Œç›´æ¥è®©æ¨¡å‹åŠ è½½å‚æ•°æƒé‡å³å¯è¿è¡Œã€‚è¿™é‡Œæ˜¯åŸºäºå“ˆåŸºç±³å£°éŸ³å¾®è°ƒçš„ğŸ˜[æ¨¡å‹æƒé‡](https://box.nju.edu.cn/d/80097b2becdc4ee788de/)ï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½è¿è¡Œã€‚

```bash
python infer.py \
--model ckpts/finetune_ckpt-v3_dit-768-12_30000steps-lr0.00005/model-step=30000.ckpt \
--input input.wav \
--output output.wav \
--speaker speaker1 \
--key-shift 0 \
--infer-steps 32 \
--batch-size 1
```

æˆ‘ä»¬å°è¯•å°†æ­Œæ›²ã€Šçˆ±é”™ã€‹ç­‰é€šè¿‡ä¸Šé¢çš„æ¨¡å‹æ–¹æ³•è½¬æ¢æˆå“ˆåŸºç±³éŸ³ä¹ï¼Œå‘ç°æ•ˆæœä¸é”™ã€‚

## utils
åˆ’åˆ†è®­ç»ƒéŸ³é¢‘ or å®ç°è½¬åŒ–åçš„ vocal ä¸ instruments èåˆ
```
python split.py
python mixed.py
```
